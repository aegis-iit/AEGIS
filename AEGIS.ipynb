{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AEGIS.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aegis-iit/AEGIS/blob/master/AEGIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL7M4ZJT6Yi2",
        "colab_type": "code",
        "outputId": "0fc9368c-c80f-472f-d647-9d80f9c8837c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4996ee3d8d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;34m': timeout during initial read of root folder; for more info: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             'https://research.google.com/colaboratory/faq.html#drive-timeout')\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Not already authorized, so do the authorization dance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PufRVGkv7l_H",
        "colab_type": "code",
        "outputId": "ac81c4a6-46b6-4d32-dfc4-831fb5195e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls \"/content/gdrive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Aegis\t AEGIS.ipynb  'Colab Notebooks'   JAVA.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLrYT1LWA_qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"gdrive/My Drive/Aegis\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S51oHFIDUK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir cocodataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZERDDzQD7bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd cocodataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQurjX7HD-zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZA5GYR6EGDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir images/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaMbgyLWEnQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir images/val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pqrJuXgEs6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir images/test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fp21C_1EzJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir annotations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2ARfRxPE8pw",
        "colab_type": "code",
        "outputId": "64c0c9af-54f2-4209-de6f-4bf17fee104b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/train2017.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-20 21:06:00--  http://images.cocodataset.org/zips/train2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.113.139\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.113.139|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19336861798 (18G) [application/zip]\n",
            "Saving to: ‘train2017.zip’\n",
            "\n",
            "train2017.zip       100%[===================>]  18.01G  47.5MB/s    in 6m 8s   \n",
            "\n",
            "2019-06-20 21:12:08 (50.2 MB/s) - ‘train2017.zip’ saved [19336861798/19336861798]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v7evaEwHKkJ",
        "colab_type": "code",
        "outputId": "7aa07b72-7859-4e41-b9b4-ee9c46ebf5f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/val2017.zip\n",
        "!wget http://images.cocodataset.org/zips/test2017.zip\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!wget http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-20 21:13:57--  http://images.cocodataset.org/zips/val2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.170.219\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.170.219|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 815585330 (778M) [application/zip]\n",
            "Saving to: ‘val2017.zip.1’\n",
            "\n",
            "val2017.zip.1       100%[===================>] 777.80M  43.8MB/s    in 17s     \n",
            "\n",
            "2019-06-20 21:14:14 (45.7 MB/s) - ‘val2017.zip.1’ saved [815585330/815585330]\n",
            "\n",
            "--2019-06-20 21:14:15--  http://images.cocodataset.org/zips/test2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.139.19\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.139.19|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6646970404 (6.2G) [application/zip]\n",
            "Saving to: ‘test2017.zip.1’\n",
            "\n",
            "test2017.zip.1      100%[===================>]   6.19G  31.9MB/s    in 3m 29s  \n",
            "\n",
            "2019-06-20 21:17:44 (30.3 MB/s) - ‘test2017.zip.1’ saved [6646970404/6646970404]\n",
            "\n",
            "--2019-06-20 21:17:45--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.185.179\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.185.179|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2017.zip.1’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  44.9MB/s    in 5.6s    \n",
            "\n",
            "2019-06-20 21:17:51 (43.4 MB/s) - ‘annotations_trainval2017.zip.1’ saved [252907541/252907541]\n",
            "\n",
            "--2019-06-20 21:17:51--  http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.108.203\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.108.203|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1148688564 (1.1G) [application/zip]\n",
            "Saving to: ‘stuff_annotations_trainval2017.zip.1’\n",
            "\n",
            "stuff_annotations_t 100%[===================>]   1.07G  46.5MB/s    in 26s     \n",
            "\n",
            "2019-06-20 21:18:17 (41.9 MB/s) - ‘stuff_annotations_trainval2017.zip.1’ saved [1148688564/1148688564]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcdoZxCHI2pp",
        "colab_type": "code",
        "outputId": "7481cb0a-7721-47f3-d69b-3317b70be007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!unzip -q val2017.zip -d images/val"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[val2017.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of val2017.zip or\n",
            "        val2017.zip.zip, and cannot find val2017.zip.ZIP, period.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMotH4G3JM9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q stuff_annotations_trainval2017.zip -d annotations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQb45aRRJlWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q train2017.zip -d images/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4hN3syTZCK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q test2017.zip -d images/test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uqRYqYjeJjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFnhdvYHeV5x",
        "colab_type": "code",
        "outputId": "5be8bf23-d178-4ed2-977f-5f2e599b77f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "USE_CUDA = True\n",
        "'''\n",
        "train_path = 'cocostuff/coco/images/train2017'\n",
        "val_path = 'cocostuf/coco/images/val2017'\n",
        "train_anno_path = 'cocostuff/coco/annotations/annotations/instances_train2017.json'\n",
        "val_anno_path = 'cocostuff/coco/annotations/annotations/instances_val2017.json'\n",
        "'''\n",
        "#train_path = 'images/train/train2017'\n",
        "val_path = 'images/val/val2017'\n",
        "#train_anno_path = 'annotations/annotations/instances_train2017.json'\n",
        "val_anno_path = 'annotations/annotations/instances_val2017.json'\n",
        "\n",
        "train_path = 'images/val/val2017'\n",
        "#val_path = 'images/val/val2017'\n",
        "train_anno_path = 'annotations/annotations/instances_val2017.json'\n",
        "#val_anno_path = 'annotations/annotations/instances_val2017.json'\n",
        "\n",
        "#### TODO replace fully connected w/ CNN for reconstruction\n",
        "#### TODO Implement regional CNN and then capsule for classification\n",
        "cellID = 77\n",
        "laptopID = 73\n",
        "def target_t(x):\n",
        "    for item in x:\n",
        "        if item['category_id'] == cellID:\n",
        "            return 1\n",
        "    return 0\n",
        "    #return x[0]['category_id']\n",
        "\n",
        "## Change this\n",
        "img_size = 64\n",
        "kernel_size = 9\n",
        "reduced = img_size-kernel_size + 1\n",
        "reduced = int((reduced-kernel_size)/2)+1\n",
        "print(reduced)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w4UVMMzigW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CocoDet:\n",
        "    def __init__(self, batch_size):\n",
        "        ds_transform = transforms.Compose([\n",
        "                       transforms.Resize((img_size,img_size)),\n",
        "                       transforms.Grayscale(),\n",
        "                       transforms.ToTensor()\n",
        "                       #transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])\n",
        "\n",
        "        train_dataset = datasets.CocoDetection(train_path, train_anno_path,\n",
        "                                               transform=ds_transform, target_transform = target_t)\n",
        "        test_dataset = datasets.CocoDetection(val_path, val_anno_path,\n",
        "                                               transform=ds_transform, target_transform = target_t)\n",
        "        #('../data', train=True, download=True, transform=dataset_transform)\n",
        "        #test_dataset = datasets.CocoCaptions(root, annFile, transform=None, target_transform=None, transforms=None)\n",
        "        #('../data', train=False, download=True, transform=dataset_transform)\n",
        "\n",
        "        self.train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        self.test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUtsvWP7i2DK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=256, kernel_size=9):\n",
        "        super(ConvLayer, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
        "                               out_channels=out_channels,\n",
        "                               kernel_size=kernel_size,\n",
        "                               stride=1\n",
        "                             )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.conv(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntEjGVtni6Pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PrimaryCaps(nn.Module):\n",
        "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32, kernel_size=9):\n",
        "        super(PrimaryCaps, self).__init__()\n",
        "\n",
        "        self.capsules = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=0) for _ in range(num_capsules)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = [capsule(x) for capsule in self.capsules]\n",
        "        u = torch.stack(u, dim=1)\n",
        "        u = u.view(x.size(0), 32 * reduced * reduced, -1)\n",
        "        return self.squash(u)\n",
        "\n",
        "    def squash(self, input_tensor):\n",
        "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
        "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
        "        return output_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n06mZHyJi-ip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DigitCaps(nn.Module):\n",
        "    def __init__(self, num_capsules=2, num_routes=32 * reduced * reduced, in_channels=8, out_channels=32):\n",
        "        super(DigitCaps, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.num_routes = num_routes\n",
        "        self.num_capsules = num_capsules\n",
        "\n",
        "        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
        "\n",
        "        W = torch.cat([self.W] * batch_size, dim=0)\n",
        "        u_hat = torch.matmul(W, x)\n",
        "\n",
        "        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n",
        "        if USE_CUDA:\n",
        "            b_ij = b_ij.cuda()\n",
        "\n",
        "        num_iterations = 3\n",
        "        for iteration in range(num_iterations):\n",
        "            c_ij = F.softmax(b_ij)\n",
        "            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
        "\n",
        "            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
        "            v_j = self.squash(s_j)\n",
        "\n",
        "            if iteration < num_iterations - 1:\n",
        "                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n",
        "                b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n",
        "\n",
        "        return v_j.squeeze(1)\n",
        "\n",
        "    def squash(self, input_tensor):\n",
        "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True) + 1e-8\n",
        "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
        "        return output_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4-jXeaLjD9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        '''\n",
        "        self.reconstraction_layers = nn.Sequential(\n",
        "            nn.Linear(16 * 2, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, img_size**2),\n",
        "            #nn.ReLU(inplace=True),\n",
        "            #nn.Linear(2048, img_size**2),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        '''\n",
        "        #img_size was 64 initially\n",
        "        self.linear = torch.nn.Linear(64, 1024*4*4)\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(\n",
        "                in_channels=1024, out_channels=512, kernel_size=4,\n",
        "                stride=2, padding=1, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(\n",
        "                in_channels=512, out_channels=256, kernel_size=4,\n",
        "                stride=2, padding=1, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(\n",
        "                in_channels=256, out_channels=128, kernel_size=4,\n",
        "                stride=2, padding=1, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(\n",
        "                in_channels=128, out_channels=1, kernel_size=4,\n",
        "                stride=2, padding=1, bias=False\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.out = torch.nn.Tanh()\n",
        "\n",
        "    def forward(self, x, data):\n",
        "        classes = torch.sqrt((x ** 2).sum(2))\n",
        "        classes = F.softmax(classes)\n",
        "\n",
        "        _, max_length_indices = classes.max(dim=1)\n",
        "        masked = Variable(torch.sparse.torch.eye(2))\n",
        "        if USE_CUDA:\n",
        "            masked = masked.cuda()\n",
        "        masked = masked.index_select(dim=0, index=max_length_indices.squeeze(1).data)\n",
        "\n",
        "        #reconstructions = self.reconstraction_layers((x * masked[:, :, None, None]).view(x.size(0), -1))\n",
        "        #reconstructions = reconstructions.view(-1, 1, img_size, img_size)\n",
        "        #multiplication by mask = way of conditioning reconstruction ?\n",
        "        rec = self.linear((x * masked[:, :, None, None]).view(x.size(0), -1))\n",
        "        rec = rec.view(rec.shape[0], 1024, 4, 4)\n",
        "        rec = self.conv1(rec)\n",
        "        rec = self.conv2(rec)\n",
        "        rec = self.conv3(rec)\n",
        "        rec = self.conv4(rec)\n",
        "        rec= self.out(rec)\n",
        "        #print(x.size())\n",
        "        #print(data.size())\n",
        "        return rec, masked\n",
        "#        return reconstructions, masked"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzDHpGuTjIXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CapsNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CapsNet, self).__init__()\n",
        "        self.conv_layer = ConvLayer()\n",
        "        self.primary_capsules = PrimaryCaps()\n",
        "        self.digit_capsules = DigitCaps()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "\n",
        "    def forward(self, data):\n",
        "        output = self.digit_capsules(self.primary_capsules(self.conv_layer(data)))\n",
        "        #print(output.sum())\n",
        "        reconstructions, masked = self.decoder(output, data)\n",
        "        return output, reconstructions, masked\n",
        "\n",
        "    def loss(self, data, x, target, reconstructions):\n",
        "        #print('ml: ', self.margin_loss(x, target))\n",
        "        #print('rec: ', self.reconstruction_loss(data, reconstructions))\n",
        "        return self.margin_loss(x, target) + self.reconstruction_loss(data, reconstructions)\n",
        "\n",
        "    def margin_loss(self, x, labels, size_average=True):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        #norm of x = probability of being each class\n",
        "        v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True))\n",
        "\n",
        "        #if prediction is correct at proba 0.9 or above\n",
        "        left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
        "        #if prediction is incorrect w/ proba 0.1 or above\n",
        "        right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
        "\n",
        "        # loss = left side if capsule corresponds to pred, right ow\n",
        "        loss = labels * left + 0.5 * (1.0 - labels) * right\n",
        "        # mean of loss on the batch\n",
        "        loss = loss.sum(dim=1).mean()\n",
        "        #print('ml: ', loss)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def reconstruction_loss(self, data, reconstructions):\n",
        "        loss = self.mse_loss(reconstructions.view(reconstructions.size(0), -1),\n",
        "                             data.view(reconstructions.size(0), -1))\n",
        "        #print 'rec: ', loss * 0.0005\n",
        "        return loss * 0.0005"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAQ3eUTDjMPr",
        "colab_type": "code",
        "outputId": "c7ec42a1-914d-4ae7-9ab6-9d629dd4c699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "capsule_net = CapsNet()\n",
        "if USE_CUDA:\n",
        "    capsule_net = capsule_net.cuda()\n",
        "optimizer = Adam(capsule_net.parameters(), lr=1e-3)\n",
        "\n",
        "n_epochs = 10\n",
        "batch_size = 32#128\n",
        "eps = 1e-7\n",
        "\n",
        "cocod = CocoDet(batch_size)\n",
        "\n",
        "\n",
        "\n",
        "total = len(cocod.train_loader)\n",
        "print('total_obs: ', total*batch_size)\n",
        "\n",
        "print('bpe: ', total)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.78s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.63s)\n",
            "creating index...\n",
            "index created!\n",
            "total_obs:  5024\n",
            "bpe:  157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6Tb8WQYmM83",
        "colab_type": "code",
        "outputId": "7c50d0df-c2b5-4bac-b7f6-dc30337a3ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4316
        }
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    capsule_net.train()\n",
        "    train_loss = 0\n",
        "    print(epoch)\n",
        "    for batch_id, (data, target) in enumerate(cocod.train_loader):\n",
        "        #print(data.type())\n",
        "        target = torch.sparse.torch.eye(2).index_select(dim=0, index=target)\n",
        "        data, target = Variable(data.float()), Variable(target.float())\n",
        "        #print(data.type())\n",
        "        if USE_CUDA:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output, reconstructions, masked = capsule_net(data)\n",
        "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()#loss.data[0]\n",
        "\n",
        "        if batch_id % 3 == 0:\n",
        "            y_pred = np.argmax(masked.data.cpu().numpy(), 1)\n",
        "            y_true = np.argmax(target.data.cpu().numpy(), 1)\n",
        "            cm = confusion_matrix(y_true,y_pred)\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "            print(cm)\n",
        "\n",
        "            print(\"train accuracy:\", sum(np.argmax(masked.data.cpu().numpy(), 1) ==\n",
        "                                   np.argmax(target.data.cpu().numpy(), 1)) / float(batch_size))\n",
        "            print(\"train precision:\", tp/(tp+fp+eps))\n",
        "            print(\"train recall:\", tp/(tp+fn+eps))\n",
        "            #print(output.sum())\n",
        "\n",
        "    print(train_loss / len(cocod.train_loader))\n",
        "    #print( np.argmax(masked.data.cpu().numpy()))\n",
        "\n",
        "    capsule_net.eval()\n",
        "    test_loss = 0\n",
        "    '''\n",
        "    for batch_id, (data, target) in enumerate(cocod.test_loader):\n",
        "\n",
        "        target = torch.sparse.torch.eye(10).index_select(dim=0, index=target)\n",
        "        data, target = Variable(data), Variable(target)\n",
        "\n",
        "        if USE_CUDA:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        output, reconstructions, masked = capsule_net(data)\n",
        "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
        "\n",
        "        test_loss += loss.item()#loss.data[0]\n",
        "\n",
        "        if batch_id % 10 == 0:\n",
        "            print(\"test accuracy:\", sum(np.argmax(masked.data.cpu().numpy(), 1) ==\n",
        "                                   np.argmax(target.data.cpu().numpy(), 1)) / float(batch_size))\n",
        "                 \n",
        "\n",
        "    print(test_loss / len(mnist.test_loader))\n",
        "    '''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[11 19]\n",
            " [ 1  1]]\n",
            "train accuracy: 0.375\n",
            "train precision: 0.049999999749999996\n",
            "train recall: 0.4999999750000013\n",
            "[[23  9]\n",
            " [ 0  0]]\n",
            "train accuracy: 0.71875\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[16 15]\n",
            " [ 0  1]]\n",
            "train accuracy: 0.53125\n",
            "train precision: 0.062499999609374995\n",
            "train recall: 0.9999999000000099\n",
            "[[19 10]\n",
            " [ 1  2]]\n",
            "train accuracy: 0.65625\n",
            "train precision: 0.1666666652777778\n",
            "train recall: 0.6666666444444452\n",
            "[[20 10]\n",
            " [ 1  1]]\n",
            "train accuracy: 0.65625\n",
            "train precision: 0.09090909008264464\n",
            "train recall: 0.4999999750000013\n",
            "[[16 11]\n",
            " [ 3  2]]\n",
            "train accuracy: 0.5625\n",
            "train precision: 0.15384615266272192\n",
            "train recall: 0.39999999200000014\n",
            "[[19 12]\n",
            " [ 1  0]]\n",
            "train accuracy: 0.59375\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[20 11]\n",
            " [ 0  1]]\n",
            "train accuracy: 0.65625\n",
            "train precision: 0.0833333326388889\n",
            "train recall: 0.9999999000000099\n",
            "[[20 11]\n",
            " [ 1  0]]\n",
            "train accuracy: 0.625\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[17 13]\n",
            " [ 2  0]]\n",
            "train accuracy: 0.53125\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[19 11]\n",
            " [ 0  2]]\n",
            "train accuracy: 0.65625\n",
            "train precision: 0.15384615266272192\n",
            "train recall: 0.9999999500000026\n",
            "[[18 14]\n",
            " [ 0  0]]\n",
            "train accuracy: 0.5625\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[19 13]\n",
            " [ 0  0]]\n",
            "train accuracy: 0.59375\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[17 13]\n",
            " [ 1  1]]\n",
            "train accuracy: 0.5625\n",
            "train precision: 0.07142857091836735\n",
            "train recall: 0.4999999750000013\n",
            "[[17 13]\n",
            " [ 0  2]]\n",
            "train accuracy: 0.59375\n",
            "train precision: 0.13333333244444445\n",
            "train recall: 0.9999999500000026\n",
            "[[19 13]\n",
            " [ 0  0]]\n",
            "train accuracy: 0.59375\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[17 13]\n",
            " [ 1  1]]\n",
            "train accuracy: 0.5625\n",
            "train precision: 0.07142857091836735\n",
            "train recall: 0.4999999750000013\n",
            "[[13 15]\n",
            " [ 4  0]]\n",
            "train accuracy: 0.40625\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[21 10]\n",
            " [ 0  1]]\n",
            "train accuracy: 0.6875\n",
            "train precision: 0.09090909008264464\n",
            "train recall: 0.9999999000000099\n",
            "[[18 14]\n",
            " [ 0  0]]\n",
            "train accuracy: 0.5625\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[18 13]\n",
            " [ 0  1]]\n",
            "train accuracy: 0.59375\n",
            "train precision: 0.07142857091836735\n",
            "train recall: 0.9999999000000099\n",
            "[[18 13]\n",
            " [ 0  1]]\n",
            "train accuracy: 0.59375\n",
            "train precision: 0.07142857091836735\n",
            "train recall: 0.9999999000000099\n",
            "[[17 12]\n",
            " [ 1  2]]\n",
            "train accuracy: 0.59375\n",
            "train precision: 0.1428571418367347\n",
            "train recall: 0.6666666444444452\n",
            "[[15 15]\n",
            " [ 0  2]]\n",
            "train accuracy: 0.53125\n",
            "train precision: 0.11764705813148789\n",
            "train recall: 0.9999999500000026\n",
            "[[14 15]\n",
            " [ 1  2]]\n",
            "train accuracy: 0.5\n",
            "train precision: 0.11764705813148789\n",
            "train recall: 0.6666666444444452\n",
            "[[17 12]\n",
            " [ 0  3]]\n",
            "train accuracy: 0.625\n",
            "train precision: 0.19999999866666668\n",
            "train recall: 0.9999999666666678\n",
            "[[13 18]\n",
            " [ 0  1]]\n",
            "train accuracy: 0.4375\n",
            "train precision: 0.052631578670360106\n",
            "train recall: 0.9999999000000099\n",
            "[[15 15]\n",
            " [ 1  1]]\n",
            "train accuracy: 0.5\n",
            "train precision: 0.062499999609374995\n",
            "train recall: 0.4999999750000013\n",
            "[[15 12]\n",
            " [ 1  4]]\n",
            "train accuracy: 0.59375\n",
            "train precision: 0.24999999843749998\n",
            "train recall: 0.7999999840000003\n",
            "[[15 16]\n",
            " [ 1  0]]\n",
            "train accuracy: 0.46875\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[16 15]\n",
            " [ 1  0]]\n",
            "train accuracy: 0.5\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[17 14]\n",
            " [ 1  0]]\n",
            "train accuracy: 0.53125\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[17 13]\n",
            " [ 1  1]]\n",
            "train accuracy: 0.5625\n",
            "train precision: 0.07142857091836735\n",
            "train recall: 0.4999999750000013\n",
            "[[17 15]\n",
            " [ 0  0]]\n",
            "train accuracy: 0.53125\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[18 12]\n",
            " [ 1  1]]\n",
            "train accuracy: 0.59375\n",
            "train precision: 0.07692307633136096\n",
            "train recall: 0.4999999750000013\n",
            "[[17 13]\n",
            " [ 0  2]]\n",
            "train accuracy: 0.59375\n",
            "train precision: 0.13333333244444445\n",
            "train recall: 0.9999999500000026\n",
            "[[13 17]\n",
            " [ 2  0]]\n",
            "train accuracy: 0.40625\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[14 16]\n",
            " [ 2  0]]\n",
            "train accuracy: 0.4375\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[20 10]\n",
            " [ 0  2]]\n",
            "train accuracy: 0.6875\n",
            "train precision: 0.1666666652777778\n",
            "train recall: 0.9999999500000026\n",
            "[[13 19]\n",
            " [ 0  0]]\n",
            "train accuracy: 0.40625\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[18 12]\n",
            " [ 1  1]]\n",
            "train accuracy: 0.59375\n",
            "train precision: 0.07692307633136096\n",
            "train recall: 0.4999999750000013\n",
            "[[23  8]\n",
            " [ 0  1]]\n",
            "train accuracy: 0.75\n",
            "train precision: 0.11111110987654323\n",
            "train recall: 0.9999999000000099\n",
            "[[20 10]\n",
            " [ 1  1]]\n",
            "train accuracy: 0.65625\n",
            "train precision: 0.09090909008264464\n",
            "train recall: 0.4999999750000013\n",
            "[[22 10]\n",
            " [ 0  0]]\n",
            "train accuracy: 0.6875\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[19 13]\n",
            " [ 0  0]]\n",
            "train accuracy: 0.59375\n",
            "train precision: 0.0\n",
            "train recall: 0.0\n",
            "[[19 12]\n",
            " [ 0  1]]\n",
            "train accuracy: 0.625\n",
            "train precision: 0.07692307633136096\n",
            "train recall: 0.9999999000000099\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}